# -*- coding: utf-8 -*-
"""StyleTransfer-Feiqi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qpQ6IvXnhptUR4FviQorGbzevQ5xbmPW

- Import libraries and frameworks
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pathlib
import matplotlib.image as mpimg
import keras
import os.path
from os import path

from keras.utils import get_file
from tensorflow.keras.applications import vgg19
from keras.utils import plot_model
from keras import Model
from datetime import datetime
from keras.optimizers import SGD

"""- Activate the use of GPU."""

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

"""- Connect Google Colab with our Google Drive."""

from google.colab import drive
import os
drive.mount('/content/gdrive/')

"""- Access the Drive folder"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/ComputationalCreativity/NeuralStyleTransfer

"""- Loading the data"""

StyleImage_data = pathlib.Path('/content/gdrive/MyDrive/ComputationalCreativity/NeuralStyleTransfer/StyleImage/StyleImage1.jpg/') 
ContentImage_data = pathlib.Path("/content/gdrive/MyDrive/ComputationalCreativity/NeuralStyleTransfer/ContentImage/ContentImage4.jpg/")

"""- Visualize the images"""

# read the image file in a numpy array
a = plt.imread(ContentImage_data)
b = plt.imread(StyleImage_data)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

"""- Obtain the Gram Matrix"""

def gram_matrix(x):
    x = tf.transpose(x, (2, 0, 1))
    features = tf.reshape(x, (tf.shape(x)[0], -1))
    gram = tf.matmul(features, tf.transpose(features))
    return gram

def style_loss(style, combination):
    S = gram_matrix(style)
    C = gram_matrix(combination)
    channels = 3
    size = img_nrows * img_ncols
    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))

def content_loss(content, combination):
    return tf.reduce_sum(tf.square(combination - content))

def total_variation_loss(x):
    a = tf.square(
        x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, 1:, : img_ncols - 1, :]
    )
    b = tf.square(
        x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, : img_nrows - 1, 1:, :]
    )
    return tf.reduce_sum(tf.pow(a + b, 1.25))

"""- Load the VGG19 Model"""

model = vgg19.VGG19(weights="imagenet", include_top=False)
model.summary()

"""- Calculate the loss functions"""

outputs_dict= dict([(layer.name, layer.output) for layer in model.layers])
feature_extractor = Model(inputs=model.inputs, outputs=outputs_dict)

Style_layer = [
    "block1_conv1",
    "block2_conv1",
    "block3_conv1",
    "block4_conv1",
    "block5_conv1",
]

Content_layer = "block5_conv2"

total_variation_weight = 1e-6
content_weight = 2.5e-8
style_weight = 1e-6

def loss_function(combination_image, ContentImage, StyleImage):

    # 1. Combine all the images in the same tensioner.
    input_tensor = tf.concat(
        [ContentImage, StyleImage, combination_image], axis=0
    )

    # 2. Get the values in all the layers for the three images.
    features = feature_extractor(input_tensor)

    #3. Inicializar the loss

    loss = tf.zeros(shape=())

    # 4. Extract the content layers + content loss
    layer_features = features[Content_layer]
    ContentImage_features = layer_features[0, :, :, :]
    combination_features = layer_features[2, :, :, :]

    loss = loss + content_weight * content_loss(
        ContentImage_features, combination_features
    )
    # 5. Extraer the style layers + style loss
    for layer_name in Style_layer:
        layer_features = features[layer_name]
        StyleImage_features = layer_features[1, :, :, :]
        combination_features = layer_features[2, :, :, :]
        sl = style_loss(StyleImage_features, combination_features)
        loss += (style_weight / len(Style_layer)) * sl
    
    loss += total_variation_weight * total_variation_loss(combination_image)

    return loss

"""- Loss optimization and gradients"""

@tf.function
def compute_loss_and_grads(combination_image, ContentImage, StyleImage):
    with tf.GradientTape() as tape:
        loss = loss_function(combination_image, ContentImage, StyleImage)
    grads = tape.gradient(loss, combination_image)
    return loss, grads

"""- Preprocess and deprocess of images"""

def preprocess_image(image_path):
    #  function to open, resize and format pictures into appropriate tensors
    img = keras.preprocessing.image.load_img(
        image_path, target_size=(img_nrows, img_ncols)
    )
    img = keras.preprocessing.image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = vgg19.preprocess_input(img)
    return tf.convert_to_tensor(img)

def deprocess_image(x):

    # Convert a tensor into an array
    x = x.reshape((img_nrows, img_ncols, 3))

    # set their mean equal to 0
    x[:, :, 0] += 103.939
    x[:, :, 1] += 116.779
    x[:, :, 2] += 123.68

    # Convert BGR to RGB.
    x = x[:, :, ::-1]

    # Make sure they are between 0 and 255
    x = np.clip(x, 0, 255).astype("uint8")

    return x

"""- Save the generated images to target folder

"""

def result_saver(iteration):
  if path.exists('/content/gdrive/MyDrive/ComputationalCreativity/NeuralStyleTransfer/Output') == False:
    os.mkdir('/content/gdrive/MyDrive/ComputationalCreativity/NeuralStyleTransfer/Output')

  os.chdir('/content/gdrive/MyDrive/ComputationalCreativity/NeuralStyleTransfer/Output')
  # Create name
  now = datetime.now()
  now = now.strftime("%Y%m%d_%H%M%S")
  #model_name = str(i) + '_' + str(now)+"_model_" + '.h5'
  image_name = str(i) + '_' + str(now)+"_image" + '.png'

  # Save image
  img = deprocess_image(combination_image.numpy())
  keras.preprocessing.image.save_img(image_name, img)

"""- Train the Neural Style transfer network """

width, height = keras.preprocessing.image.load_img(ContentImage_data).size
img_nrows = 500
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

ContentImage = preprocess_image(ContentImage_data)
StyleImage = preprocess_image(StyleImage_data)
combination_image = tf.Variable(preprocess_image(ContentImage_data))

iterations = 10000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, ContentImage, StyleImage
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 100 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        result_saver(i)

!pwd